import os
import uuid
import re
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)

def setup_directories():
    """Thi·∫øt l·∫≠p c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt"""
    directories = [
        os.getenv("CV_UPLOAD_DIR", "./uploads"),
        os.getenv("OUTPUT_DIR", "./outputs"),
        os.getenv("TEMP_DIR", "./temp")
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)

def save_uploaded_file(uploaded_file, upload_dir: str = None) -> str:
    """L∆∞u file ƒë√£ upload v√† tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n"""
    if upload_dir is None:
        upload_dir = os.getenv("CV_UPLOAD_DIR", "./uploads")
    
    Path(upload_dir).mkdir(parents=True, exist_ok=True)
    
    # T·∫°o t√™n file duy nh·∫•t
    unique_id = str(uuid.uuid4())
    file_extension = Path(uploaded_file.name).suffix
    filename = f"{unique_id}_{uploaded_file.name}"
    file_path = os.path.join(upload_dir, filename)
    
    # L∆∞u file
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    return file_path

def get_file_info(uploaded_file, file_path: str) -> Dict[str, Any]:
    """L·∫•y th√¥ng tin file"""
    return {
        "filename": uploaded_file.name,
        "path": file_path,
        "type": uploaded_file.type,
        "size": uploaded_file.size
    }

def validate_file_type(file_type: str) -> bool:
    """Ki·ªÉm tra lo·∫°i file c√≥ ƒë∆∞·ª£c h·ªó tr·ª£ hay kh√¥ng"""
    allowed_types = [
        "application/pdf",
        "image/jpeg",
        "image/jpg", 
        "image/png",
        "image/gif",
        "image/bmp",
        "image/tiff"
    ]
    return file_type in allowed_types

def format_file_size(size_bytes: int) -> str:
    """ƒê·ªãnh d·∫°ng k√≠ch th∆∞·ªõc file d·ªÖ ƒë·ªçc"""
    if size_bytes == 0:
        return "0B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def cleanup_temp_files(file_paths: List[str]):
    """D·ªçn d·∫πp c√°c file t·∫°m th·ªùi"""
    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                logger.info(f"ƒê√£ d·ªçn d·∫πp file t·∫°m: {file_path}")
        except Exception as e:
            logger.error(f"L·ªói d·ªçn d·∫πp {file_path}: {e}")

def generate_session_id() -> str:
    """T·∫°o ID session duy nh·∫•t"""
    return str(uuid.uuid4())

def truncate_text(text: str, max_length: int = 100) -> str:
    """C·∫Øt ng·∫Øn text ƒë·∫øn ƒë·ªô d√†i ch·ªâ ƒë·ªãnh"""
    if len(text) <= max_length:
        return text
    return text[:max_length] + "..."

def format_score(score: float) -> str:
    """ƒê·ªãnh d·∫°ng ƒëi·ªÉm s·ªë v·ªõi m√†u s·∫Øc ph√π h·ª£p"""
    if score >= 8:
        return f"üü¢ {score:.1f}"
    elif score >= 6:
        return f"üü° {score:.1f}"
    else:
        return f"üî¥ {score:.1f}"

def get_pass_status_emoji(is_passed: bool) -> str:
    """L·∫•y emoji cho tr·∫°ng th√°i ƒë·∫°t/kh√¥ng ƒë·∫°t"""
    return "‚úÖ" if is_passed else "‚ùå"

def create_download_link(data: str, filename: str, text: str = "T·∫£i xu·ªëng") -> str:
    """T·∫°o link t·∫£i xu·ªëng cho d·ªØ li·ªáu"""
    import base64
    
    b64 = base64.b64encode(data.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="{filename}">{text}</a>'
    return href

def parse_job_requirements(job_description: str) -> Dict[str, List[str]]:
    """Ph√¢n t√≠ch y√™u c·∫ßu c√¥ng vi·ªác t·ª´ m√¥ t·∫£ c√¥ng vi·ªác"""
    requirements = {
        "skills": [],
        "experience": [],
        "education": [],
        "languages": []
    }
    
    # Ph√¢n t√≠ch ƒë∆°n gi·∫£n d·ª±a tr√™n t·ª´ kh√≥a
    text = job_description.lower()
    
    # T·ª´ kh√≥a k·ªπ nƒÉng ph·ªï bi·∫øn (c·∫≠p nh·∫≠t cho ti·∫øng Vi·ªát)
    skill_keywords = [
        "python", "java", "javascript", "react", "nodejs", "mysql", "postgresql",
        "docker", "kubernetes", "aws", "azure", "git", "html", "css", "php",
        "laravel", "django", "flask", "vue", "angular", "mongodb", "redis",
        "machine learning", "ai", "data science", "blockchain", "devops",
        "spring boot", "hibernate", "microservices", "restful api", "graphql",
        "typescript", "webpack", "babel", "sass", "less", "bootstrap",
        "tailwind", "figma", "photoshop", "illustrator", "sketch",
        "unity", "unreal engine", "android", "ios", "swift", "kotlin",
        "flutter", "react native", "xamarin", "firebase", "supabase",
        "tensorflow", "pytorch", "scikit-learn", "pandas", "numpy",
        "tableau", "power bi", "excel", "word", "powerpoint",
        "agile", "scrum", "kanban", "jira", "confluence", "trello"
    ]
    
    for skill in skill_keywords:
        if skill in text:
            requirements["skills"].append(skill)
    
    # T·ª´ kh√≥a kinh nghi·ªám (c·∫≠p nh·∫≠t cho ti·∫øng Vi·ªát)
    experience_keywords = [
        "nƒÉm kinh nghi·ªám", "years experience", "kinh nghi·ªám", "experience",
        "l√†m vi·ªác", "work", "d·ª± √°n", "project", "th·ª±c t·∫≠p", "internship",
        "part-time", "full-time", "freelance", "t∆∞ v·∫•n", "consulting"
    ]
    
    if any(keyword in text for keyword in experience_keywords):
        requirements["experience"].append("C√≥ kinh nghi·ªám l√†m vi·ªác")
    
    # T·ª´ kh√≥a h·ªçc v·∫•n (c·∫≠p nh·∫≠t cho ti·∫øng Vi·ªát)
    education_keywords = [
        "ƒë·∫°i h·ªçc", "university", "bachelor", "th·∫°c sƒ©", "master", "ti·∫øn sƒ©", "phd",
        "cao ƒë·∫≥ng", "college", "trung c·∫•p", "diploma", "ch·ª©ng ch·ªâ", "certificate",
        "b·∫±ng c·∫•p", "degree", "h·ªçc v·∫•n", "education", "t·ªët nghi·ªáp", "graduate"
    ]
    
    if any(keyword in text for keyword in education_keywords):
        requirements["education"].append("T·ªët nghi·ªáp ƒë·∫°i h·ªçc tr·ªü l√™n")
    
    # T·ª´ kh√≥a ng√¥n ng·ªØ (c·∫≠p nh·∫≠t cho ti·∫øng Vi·ªát)
    language_keywords = [
        "ti·∫øng anh", "english", "ielts", "toeic", "toefl", "chinese", "ti·∫øng trung",
        "japanese", "ti·∫øng nh·∫≠t", "korean", "ti·∫øng h√†n", "french", "ti·∫øng ph√°p",
        "german", "ti·∫øng ƒë·ª©c", "spanish", "ti·∫øng t√¢y ban nha", "multilingual",
        "bilingual", "ƒëa ng√¥n ng·ªØ", "song ng·ªØ"
    ]
    
    if any(keyword in text for keyword in language_keywords):
        requirements["languages"].append("Ti·∫øng Anh ho·∫∑c ngo·∫°i ng·ªØ kh√°c")
    
    return requirements

def estimate_processing_time(num_files: int) -> str:
    """∆Ø·ªõc t√≠nh th·ªùi gian x·ª≠ l√Ω d·ª±a tr√™n s·ªë file"""
    # ∆Ø·ªõc t√≠nh th√¥: 15 gi√¢y m·ªói file v·ªõi GPT-3.5-turbo (nhanh h∆°n)
    total_seconds = num_files * 15
    
    if total_seconds < 60:
        return f"~{total_seconds} gi√¢y"
    elif total_seconds < 3600:
        minutes = total_seconds // 60
        return f"~{minutes} ph√∫t"
    else:
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        return f"~{hours} gi·ªù {minutes} ph√∫t"

def create_progress_callback(progress_bar, total_steps: int, current_step: int = 0):
    """T·∫°o h√†m callback cho progress"""
    def update_progress(step_name: str):
        nonlocal current_step
        current_step += 1
        progress = current_step / total_steps
        progress_bar.progress(progress, text=f"ƒêang x·ª≠ l√Ω: {step_name}")
    
    return update_progress

def format_datetime(datetime_str: str) -> str:
    """ƒê·ªãnh d·∫°ng chu·ªói datetime ƒë·ªÉ hi·ªÉn th·ªã theo ƒë·ªãnh d·∫°ng Vi·ªát Nam"""
    from datetime import datetime
    
    try:
        # X·ª≠ l√Ω c√°c ƒë·ªãnh d·∫°ng datetime kh√°c nhau
        if 'T' in datetime_str:
            dt = datetime.fromisoformat(datetime_str.replace('Z', '+00:00'))
        else:
            # Th·ª≠ parse v·ªõi ƒë·ªãnh d·∫°ng ph·ªï bi·∫øn
            try:
                dt = datetime.strptime(datetime_str, "%Y-%m-%d %H:%M:%S")
            except:
                dt = datetime.strptime(datetime_str, "%Y-%m-%d")
        
        # Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng Vi·ªát Nam
        return dt.strftime("%d/%m/%Y %H:%M")
    except:
        return datetime_str

def get_file_icon(file_type: str) -> str:
    """L·∫•y icon ph√π h·ª£p cho lo·∫°i file"""
    if file_type == "application/pdf":
        return "üìÑ"
    elif file_type.startswith("image/"):
        return "üñºÔ∏è"
    elif file_type.startswith("text/"):
        return "üìù"
    elif file_type.startswith("application/vnd.ms-excel") or file_type.startswith("application/vnd.openxmlformats-officedocument.spreadsheetml"):
        return "üìä"
    elif file_type.startswith("application/msword") or file_type.startswith("application/vnd.openxmlformats-officedocument.wordprocessingml"):
        return "üìÑ"
    else:
        return "üìÅ"

def get_score_color(score: float) -> str:
    """L·∫•y m√†u s·∫Øc cho ƒëi·ªÉm s·ªë"""
    if score >= 8:
        return "green"
    elif score >= 6:
        return "orange"
    else:
        return "red"

def format_percentage(value: float) -> str:
    """ƒê·ªãnh d·∫°ng ph·∫ßn trƒÉm"""
    return f"{value:.1f}%"

def get_qualification_status(is_qualified: bool) -> str:
    """L·∫•y tr·∫°ng th√°i ƒë·∫°t/kh√¥ng ƒë·∫°t y√™u c·∫ßu"""
    return "ƒê·∫°t y√™u c·∫ßu" if is_qualified else "Kh√¥ng ƒë·∫°t y√™u c·∫ßu"

def get_qualification_status_emoji(is_qualified: bool) -> str:
    """L·∫•y emoji cho tr·∫°ng th√°i ƒë·∫°t/kh√¥ng ƒë·∫°t y√™u c·∫ßu"""
    return "‚úÖ ƒê·∫°t y√™u c·∫ßu" if is_qualified else "‚ùå Kh√¥ng ƒë·∫°t y√™u c·∫ßu"

def create_summary_stats(results: List[Dict]) -> Dict:
    """T·∫°o th·ªëng k√™ t√≥m t·∫Øt t·ª´ k·∫øt qu·∫£"""
    if not results:
        return {
            "total": 0,
            "qualified": 0,
            "average_score": 0,
            "qualification_rate": 0,
            "highest_score": 0,
            "lowest_score": 0
        }
    
    total = len(results)
    qualified = sum(1 for r in results if r.get('is_qualified', False))
    scores = [r.get('score', 0) for r in results]
    
    return {
        "total": total,
        "qualified": qualified,
        "average_score": round(sum(scores) / total, 2),
        "qualification_rate": round(qualified / total * 100, 1),
        "highest_score": max(scores) if scores else 0,
        "lowest_score": min(scores) if scores else 0
    }

def validate_session_data(session_data: Dict) -> bool:
    """Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa d·ªØ li·ªáu session"""
    required_fields = ['session_id', 'job_description', 'required_candidates']
    return all(field in session_data for field in required_fields)

def sanitize_filename(filename: str) -> str:
    """L√†m s·∫°ch t√™n file ƒë·ªÉ ƒë·∫£m b·∫£o an to√†n"""
    import re
    # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng an to√†n
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    # Lo·∫°i b·ªè d·∫•u ti·∫øng Vi·ªát ƒë·ªÉ tr√°nh l·ªói encoding
    vietnamese_chars = {
        '√†': 'a', '√°': 'a', '·∫°': 'a', '·∫£': 'a', '√£': 'a', '√¢': 'a', '·∫ß': 'a', '·∫•': 'a', '·∫≠': 'a', '·∫©': 'a', '·∫´': 'a', 'ƒÉ': 'a', '·∫±': 'a', '·∫Ø': 'a', '·∫∑': 'a', '·∫≥': 'a', '·∫µ': 'a',
        '√®': 'e', '√©': 'e', '·∫π': 'e', '·∫ª': 'e', '·∫Ω': 'e', '√™': 'e', '·ªÅ': 'e', '·∫ø': 'e', '·ªá': 'e', '·ªÉ': 'e', '·ªÖ': 'e',
        '√¨': 'i', '√≠': 'i', '·ªã': 'i', '·ªâ': 'i', 'ƒ©': 'i',
        '√≤': 'o', '√≥': 'o', '·ªç': 'o', '·ªè': 'o', '√µ': 'o', '√¥': 'o', '·ªì': 'o', '·ªë': 'o', '·ªô': 'o', '·ªï': 'o', '·ªó': 'o', '∆°': 'o', '·ªù': 'o', '·ªõ': 'o', '·ª£': 'o', '·ªü': 'o', '·ª°': 'o',
        '√π': 'u', '√∫': 'u', '·ª•': 'u', '·ªß': 'u', '≈©': 'u', '∆∞': 'u', '·ª´': 'u', '·ª©': 'u', '·ª±': 'u', '·ª≠': 'u', '·ªØ': 'u',
        '·ª≥': 'y', '√Ω': 'y', '·ªµ': 'y', '·ª∑': 'y', '·ªπ': 'y',
        'ƒë': 'd',
        '√Ä': 'A', '√Å': 'A', '·∫†': 'A', '·∫¢': 'A', '√É': 'A', '√Ç': 'A', '·∫¶': 'A', '·∫§': 'A', '·∫¨': 'A', '·∫®': 'A', '·∫™': 'A', 'ƒÇ': 'A', '·∫∞': 'A', '·∫Æ': 'A', '·∫∂': 'A', '·∫≤': 'A', '·∫¥': 'A',
        '√à': 'E', '√â': 'E', '·∫∏': 'E', '·∫∫': 'E', '·∫º': 'E', '√ä': 'E', '·ªÄ': 'E', '·∫æ': 'E', '·ªÜ': 'E', '·ªÇ': 'E', '·ªÑ': 'E',
        '√å': 'I', '√ç': 'I', '·ªä': 'I', '·ªà': 'I', 'ƒ®': 'I',
        '√í': 'O', '√ì': 'O', '·ªå': 'O', '·ªé': 'O', '√ï': 'O', '√î': 'O', '·ªí': 'O', '·ªê': 'O', '·ªò': 'O', '·ªî': 'O', '·ªñ': 'O', '∆†': 'O', '·ªú': 'O', '·ªö': 'O', '·ª¢': 'O', '·ªû': 'O', '·ª†': 'O',
        '√ô': 'U', '√ö': 'U', '·ª§': 'U', '·ª¶': 'U', '≈®': 'U', '∆Ø': 'U', '·ª™': 'U', '·ª®': 'U', '·ª∞': 'U', '·ª¨': 'U', '·ªÆ': 'U',
        '·ª≤': 'Y', '√ù': 'Y', '·ª¥': 'Y', '·ª∂': 'Y', '·ª∏': 'Y',
        'ƒê': 'D'
    }
    
    for vietnamese, english in vietnamese_chars.items():
        filename = filename.replace(vietnamese, english)
    
    # Gi·ªõi h·∫°n ƒë·ªô d√†i
    if len(filename) > 100:
        name, ext = os.path.splitext(filename)
        filename = name[:95] + ext
        
    return filename

def log_evaluation_metrics(session_id: str, metrics: Dict):
    """Ghi log c√°c metrics ƒë√°nh gi√°"""
    logger.info(f"Phi√™n {session_id} - Metrics: {metrics}")

def create_error_response(error_message: str) -> Dict:
    """T·∫°o ph·∫£n h·ªìi l·ªói chu·∫©n"""
    return {
        "success": False,
        "error": error_message,
        "timestamp": str(uuid.uuid4())
    }

def create_success_response(data: Any, message: str = "Th√†nh c√¥ng") -> Dict:
    """T·∫°o ph·∫£n h·ªìi th√†nh c√¥ng chu·∫©n"""
    return {
        "success": True,
        "data": data,
        "message": message,
        "timestamp": str(uuid.uuid4())
    }

def validate_email(email: str) -> bool:
    """Ki·ªÉm tra ƒë·ªãnh d·∫°ng email h·ª£p l·ªá"""
    import re
    pattern = r'^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$'
    return re.match(pattern, email) is not None

def generate_random_password(length: int = 12) -> str:
    """T·∫°o m·∫≠t kh·∫©u ng·∫´u nhi√™n"""
    import random
    import string
    
    characters = string.ascii_letters + string.digits + "!@#$%^&*"
    password = ''.join(random.choice(characters) for _ in range(length))
    return password

def calculate_cv_match_percentage(cv_skills: List[str], job_requirements: List[str]) -> float:
    """T√≠nh ph·∫ßn trƒÉm kh·ªõp gi·ªØa k·ªπ nƒÉng CV v√† y√™u c·∫ßu c√¥ng vi·ªác"""
    if not job_requirements:
        return 0.0
    
    cv_skills_lower = [skill.lower().strip() for skill in cv_skills]
    job_requirements_lower = [req.lower().strip() for req in job_requirements]
    
    matches = sum(1 for req in job_requirements_lower if any(req in skill or skill in req for skill in cv_skills_lower))
    
    return (matches / len(job_requirements)) * 100

def extract_years_of_experience(cv_text: str) -> int:
    """Tr√≠ch xu·∫•t s·ªë nƒÉm kinh nghi·ªám t·ª´ CV"""
    import re
    
    # C√°c pattern ƒë·ªÉ t√¨m nƒÉm kinh nghi·ªám
    patterns = [
        r'(\d+)\s*nƒÉm\s*kinh\s*nghi·ªám',
        r'(\d+)\s*years?\s*of?\s*experience',
        r'(\d+)\s*years?\s*experience',
        r'kinh\s*nghi·ªám\s*(\d+)\s*nƒÉm',
        r'experience\s*[:\-]\s*(\d+)\s*years?'
    ]
    
    years = []
    text_lower = cv_text.lower()
    
    for pattern in patterns:
        matches = re.findall(pattern, text_lower)
        years.extend([int(match) for match in matches])
    
    # Tr·∫£ v·ªÅ nƒÉm kinh nghi·ªám cao nh·∫•t t√¨m ƒë∆∞·ª£c
    return max(years) if years else 0

def format_currency_vnd(amount: float) -> str:
    """ƒê·ªãnh d·∫°ng ti·ªÅn t·ªá VND"""
    if amount >= 1_000_000_000:
        return f"{amount/1_000_000_000:.1f} t·ª∑ VND"
    elif amount >= 1_000_000:
        return f"{amount/1_000_000:.1f} tri·ªáu VND"
    else:
        return f"{amount:,.0f} VND"

def get_experience_level(years: int) -> str:
    """X√°c ƒë·ªãnh c·∫•p ƒë·ªô kinh nghi·ªám"""
    if years == 0:
        return "Fresher/M·ªõi t·ªët nghi·ªáp"
    elif years <= 2:
        return "Junior (1-2 nƒÉm)"
    elif years <= 5:
        return "Middle (3-5 nƒÉm)"
    elif years <= 10:
        return "Senior (6-10 nƒÉm)"
    else:
        return "Expert (10+ nƒÉm)"

def create_evaluation_summary(evaluations: List[Dict]) -> Dict:
    """T·∫°o t√≥m t·∫Øt ƒë√°nh gi√° to√†n di·ªán"""
    if not evaluations:
        return {
            "message": "Kh√¥ng c√≥ d·ªØ li·ªáu ƒë√°nh gi√°",
            "stats": {}
        }
    
    stats = create_summary_stats(evaluations)
    
    # Ph√¢n t√≠ch th√™m
    score_ranges = {
        "excellent": sum(1 for e in evaluations if e.get('score', 0) >= 9),
        "good": sum(1 for e in evaluations if 7 <= e.get('score', 0) < 9),
        "average": sum(1 for e in evaluations if 5 <= e.get('score', 0) < 7),
        "poor": sum(1 for e in evaluations if e.get('score', 0) < 5)
    }
    
    # Top skills t·ª´ c√°c CV
    all_skills = []
    for eval in evaluations:
        eval_text = eval.get('evaluation_text', '')
        if eval_text:
            try:
                import json
                eval_data = json.loads(eval_text)
                if isinstance(eval_data, dict):
                    strengths = eval_data.get('ƒêi·ªÉm m·∫°nh', [])
                    all_skills.extend(strengths)
            except:
                pass
    
    # ƒê·∫øm skill ph·ªï bi·∫øn
    from collections import Counter
    skill_counter = Counter(all_skills)
    popular_skills = skill_counter.most_common(10)
    
    return {
        "total_candidates": len(evaluations),
        "qualified_candidates": stats["qualified"],
        "qualification_rate": stats["qualification_rate"],
        "average_score": stats["average_score"],
        "score_distribution": score_ranges,
        "popular_skills": popular_skills,
        "recommendations": generate_hiring_recommendations(evaluations)
    }

def generate_hiring_recommendations(evaluations: List[Dict]) -> List[str]:
    """T·∫°o khuy·∫øn ngh·ªã tuy·ªÉn d·ª•ng"""
    recommendations = []
    
    if not evaluations:
        return ["Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë∆∞a ra khuy·∫øn ngh·ªã"]
    
    qualified = [e for e in evaluations if e.get('is_qualified', False)]
    total = len(evaluations)
    qualified_count = len(qualified)
    
    # Khuy·∫øn ngh·ªã d·ª±a tr√™n t·ª∑ l·ªá ƒë·∫°t y√™u c·∫ßu
    if qualified_count == 0:
        recommendations.extend([
            "Kh√¥ng c√≥ ·ª©ng vi√™n n√†o ƒë·∫°t y√™u c·∫ßu hi·ªán t·∫°i",
            "Xem x√©t gi·∫£m b·ªõt y√™u c·∫ßu ho·∫∑c m·ªü r·ªông ph·∫°m vi t√¨m ki·∫øm",
            "C·∫ßn ƒë√†o t·∫°o th√™m cho c√°c ·ª©ng vi√™n ti·ªÅm nƒÉng"
        ])
    elif qualified_count / total < 0.2:
        recommendations.extend([
            "T·ª∑ l·ªá ·ª©ng vi√™n ƒë·∫°t y√™u c·∫ßu th·∫•p (<20%)",
            "Xem x√©t ƒëi·ªÅu ch·ªânh ti√™u ch√≠ tuy·ªÉn d·ª•ng",
            "T·∫≠p trung ph·ªèng v·∫•n nh·ªØng ·ª©ng vi√™n c√≥ ƒëi·ªÉm cao nh·∫•t"
        ])
    elif qualified_count / total > 0.5:
        recommendations.extend([
            "C√≥ nhi·ªÅu ·ª©ng vi√™n ch·∫•t l∆∞·ª£ng (>50% ƒë·∫°t y√™u c·∫ßu)",
            "C√≥ th·ªÉ n√¢ng cao ti√™u ch√≠ ƒë·ªÉ l·ªçc t·ªët h∆°n",
            "Xem x√©t tuy·ªÉn th√™m cho c√°c v·ªã tr√≠ t∆∞∆°ng t·ª±"
        ])
    
    # Khuy·∫øn ngh·ªã d·ª±a tr√™n ƒëi·ªÉm s·ªë
    scores = [e.get('score', 0) for e in evaluations]
    avg_score = sum(scores) / len(scores)
    
    if avg_score >= 7:
        recommendations.append("Ch·∫•t l∆∞·ª£ng ·ª©ng vi√™n t·ªïng th·ªÉ t·ªët, n√™n tuy·ªÉn nh·ªØng ng∆∞·ªùi c√≥ ƒëi·ªÉm cao nh·∫•t")
    elif avg_score >= 5:
        recommendations.append("Ch·∫•t l∆∞·ª£ng ·ª©ng vi√™n trung b√¨nh, c·∫ßn ph·ªèng v·∫•n k·ªπ ƒë·ªÉ ƒë√°nh gi√° th√™m")
    else:
        recommendations.append("Ch·∫•t l∆∞·ª£ng ·ª©ng vi√™n ch∆∞a cao, c·∫ßn m·ªü r·ªông t√¨m ki·∫øm ho·∫∑c ƒë√†o t·∫°o")
    
    return recommendations

def create_detailed_candidate_report(candidate_data: Dict) -> str:
    """T·∫°o b√°o c√°o chi ti·∫øt cho t·ª´ng ·ª©ng vi√™n"""
    try:
        filename = candidate_data.get('filename', '·ª®ng vi√™n')
        score = candidate_data.get('score', 0)
        is_qualified = candidate_data.get('is_qualified', False)
        evaluation_text = candidate_data.get('evaluation_text', '')
        
        report = f"""
        üìã B√ÅO C√ÅO CHI TI·∫æT ·ª®NG VI√äN
        
        üë§ T√™n file CV: {filename}
        üìä ƒêi·ªÉm t·ªïng: {score:.1f}/10
        ‚úÖ Tr·∫°ng th√°i: {get_qualification_status_emoji(is_qualified)}
        
        """
        
        # Ph√¢n t√≠ch ƒë√°nh gi√° n·∫øu c√≥
        if evaluation_text:
            try:
                import json
                eval_data = json.loads(evaluation_text)
                if isinstance(eval_data, dict):
                    report += f"""
        üéØ PH√ÇN T√çCH CHI TI·∫æT:
        
        üìà ƒêi·ªÉm t·ª´ng ti√™u ch√≠:
        - Ph√π h·ª£p v·ªõi c√¥ng vi·ªác: {eval_data.get('C√°c ti√™u ch√≠', {}).get('ƒêi·ªÉm ph√π h·ª£p', 0)}/10
        - Kinh nghi·ªám: {eval_data.get('C√°c ti√™u ch√≠', {}).get('ƒêi·ªÉm kinh nghi·ªám', 0)}/10
        - K·ªπ nƒÉng: {eval_data.get('C√°c ti√™u ch√≠', {}).get('ƒêi·ªÉm kƒ© nƒÉng', 0)}/10
        - H·ªçc v·∫•n: {eval_data.get('C√°c ti√™u ch√≠', {}).get('ƒêi·ªÉm gi√°o d·ª•c', 0)}/10
        
        üí™ ƒêi·ªÉm m·∫°nh:
        """
                    strengths = eval_data.get('ƒêi·ªÉm m·∫°nh', [])
                    for i, strength in enumerate(strengths, 1):
                        report += f"        {i}. {strength}\n"
                    
                    report += f"""
        ‚ö†Ô∏è ƒêi·ªÉm c·∫ßn c·∫£i thi·ªán:
        """
                    weaknesses = eval_data.get('ƒêi·ªÉm y·∫øu', [])
                    for i, weakness in enumerate(weaknesses, 1):
                        report += f"        {i}. {weakness}\n"
                    
                    report += f"""
        üìù T·ªïng k·∫øt: {eval_data.get('T·ªïng k·∫øt', '')}
        """
            except:
                report += f"\nüìÑ ƒê√°nh gi√°: {evaluation_text[:500]}..."
        
        report += f"""
        
        ‚è∞ Th·ªùi gian t·∫°o b√°o c√°o: {format_datetime(str(uuid.uuid4()))}
        üéØ H·ªá th·ªëng: CV Evaluator AI
        """
        
        return report
        
    except Exception as e:
        logger.error(f"L·ªói t·∫°o b√°o c√°o ·ª©ng vi√™n: {e}")
        return f"L·ªói t·∫°o b√°o c√°o: {str(e)}"

def generate_session_title(position_title: str, job_description: str) -> str:
    """T·ª± ƒë·ªông t·∫°o title cho session d·ª±a tr√™n v·ªã tr√≠ v√† m√¥ t·∫£ c√¥ng vi·ªác"""
    try:
        # L√†m s·∫°ch position title
        clean_position = position_title.strip() if position_title else ""
        
        # N·∫øu c√≥ position title, s·ª≠ d·ª•ng l√†m base
        if clean_position:
            base_title = clean_position
        else:
            # Tr√≠ch xu·∫•t v·ªã tr√≠ t·ª´ job description
            base_title = extract_position_from_jd(job_description)
        
        # Th√™m timestamp ƒë·ªÉ ƒë·∫£m b·∫£o unique
        timestamp = datetime.now().strftime("%d/%m %H:%M")
        
        # T·∫°o title cu·ªëi c√πng
        if base_title:
            # Gi·ªõi h·∫°n ƒë·ªô d√†i position title
            if len(base_title) > 30:
                base_title = base_title[:27] + "..."
            session_title = f"{base_title} - {timestamp}"
        else:
            session_title = f"Tuy·ªÉn d·ª•ng - {timestamp}"
        
        return session_title
        
    except Exception as e:
        logger.error(f"L·ªói t·∫°o session title: {e}")
        # Fallback title
        return f"Phi√™n tuy·ªÉn d·ª•ng - {datetime.now().strftime('%d/%m %H:%M')}"

def extract_position_from_jd(job_description: str) -> str:
    """Tr√≠ch xu·∫•t t√™n v·ªã tr√≠ t·ª´ m√¥ t·∫£ c√¥ng vi·ªác"""
    try:
        if not job_description:
            return ""
        
        text = job_description.lower()
        
        # C√°c pattern ƒë·ªÉ t√¨m v·ªã tr√≠
        position_patterns = [
            r'v·ªã\s*tr√≠[:\s]+([^.\n]+)',
            r'position[:\s]+([^.\n]+)',
            r'tuy·ªÉn\s*d·ª•ng[:\s]+([^.\n]+)',
            r'hiring[:\s]+([^.\n]+)',
            r'c·∫ßn\s*t√¨m[:\s]+([^.\n]+)',
            r't√¨m\s*ki·∫øm[:\s]+([^.\n]+)',
        ]
        
        for pattern in position_patterns:
            match = re.search(pattern, text)
            if match:
                position = match.group(1).strip()
                # L√†m s·∫°ch v√† chu·∫©n h√≥a
                position = re.sub(r'[^\w\s\-]+', '', position)
                if len(position) > 5 and len(position) < 50:
                    return position.title()
        
        # N·∫øu kh√¥ng t√¨m th·∫•y pattern, t√¨m keywords ph·ªï bi·∫øn
        common_positions = [
            'developer', 'l·∫≠p tr√¨nh vi√™n', 'programmer', 'engineer', 'k·ªπ s∆∞',
            'designer', 'thi·∫øt k·∫ø', 'manager', 'qu·∫£n l√Ω', 'leader', 'tr∆∞·ªüng',
            'analyst', 'ph√¢n t√≠ch', 'tester', 'qa', 'ki·ªÉm th·ª≠',
            'marketer', 'marketing', 'sales', 'b√°n h√†ng', 'hr', 'nh√¢n s·ª±',
            'accountant', 'k·∫ø to√°n', 'finance', 't√†i ch√≠nh',
            'product owner', 'scrum master', 'devops', 'fullstack',
            'frontend', 'backend', 'mobile', 'web', 'ai', 'data'
        ]
        
        for position in common_positions:
            if position in text:
                return position.title()
        
        # N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y, tr·∫£ v·ªÅ empty
        return ""
        
    except Exception as e:
        logger.error(f"L·ªói tr√≠ch xu·∫•t v·ªã tr√≠ t·ª´ JD: {e}")
        return ""

def generate_smart_session_title(position_title: str, job_description: str, required_candidates: int) -> str:
    """T·∫°o title th√¥ng minh h∆°n v·ªõi th√™m th√¥ng tin"""
    try:
        # L·∫•y base title
        base_title = generate_session_title(position_title, job_description)
        
        # Th√™m th√¥ng tin s·ªë l∆∞·ª£ng tuy·ªÉn d·ª•ng
        if required_candidates > 1:
            base_title = f"{base_title} ({required_candidates} ng∆∞·ªùi)"
        
        # Th√™m keywords n·ªïi b·∫≠t t·ª´ JD
        keywords = extract_key_skills_from_jd(job_description)
        if keywords:
            # Ch·ªâ l·∫•y 2 keywords ƒë·∫ßu v√† gi·ªõi h·∫°n ƒë·ªô d√†i
            key_skills = " | ".join(keywords[:2])
            if len(key_skills) < 20:
                base_title = f"{base_title} | {key_skills}"
        
        return base_title
        
    except Exception as e:
        logger.error(f"L·ªói t·∫°o smart session title: {e}")
        return generate_session_title(position_title, job_description)

def extract_key_skills_from_jd(job_description: str) -> List[str]:
    """Tr√≠ch xu·∫•t k·ªπ nƒÉng ch√≠nh t·ª´ JD"""
    try:
        if not job_description:
            return []
        
        text = job_description.lower()
        
        # K·ªπ nƒÉng tech ph·ªï bi·∫øn
        tech_skills = [
            'python', 'java', 'javascript', 'react', 'nodejs', 'php',
            'mysql', 'postgresql', 'mongodb', 'docker', 'kubernetes',
            'aws', 'azure', 'git', 'agile', 'scrum', 'devops',
            'html', 'css', 'vue', 'angular', 'laravel', 'django',
            'machine learning', 'ai', 'data science', 'blockchain',
            'flutter', 'react native', 'ios', 'android', 'unity'
        ]
        
        # K·ªπ nƒÉng soft
        soft_skills = [
            'leadership', 'l√£nh ƒë·∫°o', 'communication', 'giao ti·∫øp',
            'teamwork', 'l√†m vi·ªác nh√≥m', 'problem solving', 'gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ'
        ]
        
        found_skills = []
        
        # T√¨m tech skills tr∆∞·ªõc
        for skill in tech_skills:
            if skill in text and skill not in found_skills:
                found_skills.append(skill.title())
                if len(found_skills) >= 3:
                    break
        
        # N·∫øu kh√¥ng ƒë·ªß tech skills, th√™m soft skills
        if len(found_skills) < 2:
            for skill in soft_skills:
                if skill in text and skill not in found_skills:
                    found_skills.append(skill.title())
                    if len(found_skills) >= 2:
                        break
        
        return found_skills
        
    except Exception as e:
        logger.error(f"L·ªói tr√≠ch xu·∫•t skills t·ª´ JD: {e}")
        return []

def format_session_title_for_display(session_title: str, max_length: int = 50) -> str:
    """Format session title ƒë·ªÉ hi·ªÉn th·ªã trong UI"""
    try:
        if not session_title:
            return "Phi√™n kh√¥ng c√≥ t√™n"
        
        # C·∫Øt ng·∫Øn n·∫øu qu√° d√†i
        if len(session_title) > max_length:
            return session_title[:max_length-3] + "..."
        
        return session_title
        
    except Exception as e:
        logger.error(f"L·ªói format session title: {e}")
        return "Phi√™n tuy·ªÉn d·ª•ng"

def get_session_display_name(session_data: dict) -> str:
    """L·∫•y t√™n hi·ªÉn th·ªã cho session"""
    try:
        # ∆Øu ti√™n session_title n·∫øu c√≥
        if session_data.get('session_title'):
            return format_session_title_for_display(session_data['session_title'])
        
        # Fallback: t·∫°o t·ª´ position_title
        if session_data.get('position_title'):
            position = session_data['position_title']
            if len(position) > 30:
                position = position[:27] + "..."
            return f"{position} - {session_data.get('session_id', '')[:8]}"
        
        # Fallback cu·ªëi: session_id
        session_id = session_data.get('session_id', '')
        return f"Phi√™n {session_id[:8]}..." if session_id else "Phi√™n kh√¥ng x√°c ƒë·ªãnh"
        
    except Exception as e:
        logger.error(f"L·ªói l·∫•y session display name: {e}")
        return "Phi√™n tuy·ªÉn d·ª•ng"

# Th√™m validation cho session title
def validate_session_title(title: str) -> bool:
    """Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa session title"""
    try:
        if not title or len(title.strip()) == 0:
            return False
        
        # Ki·ªÉm tra ƒë·ªô d√†i
        if len(title) > 100:
            return False
        
        # Ki·ªÉm tra k√Ω t·ª± ƒë·∫∑c bi·ªát nguy hi·ªÉm
        dangerous_chars = ['<', '>', '"', "'", '&', ';']
        if any(char in title for char in dangerous_chars):
            return False
        
        return True
        
    except Exception as e:
        logger.error(f"L·ªói validate session title: {e}")
        return False

def create_session_title_suggestions(job_description: str) -> List[str]:
    """T·∫°o g·ª£i √Ω title cho session"""
    try:
        suggestions = []
        
        # G·ª£i √Ω 1: T·ª´ position trong JD
        position = extract_position_from_jd(job_description)
        if position:
            suggestions.append(f"Tuy·ªÉn {position}")
        
        # G·ª£i √Ω 2: V·ªõi skills ch√≠nh
        skills = extract_key_skills_from_jd(job_description)
        if skills:
            suggestions.append(f"Tuy·ªÉn {' & '.join(skills[:2])} Developer")
        
        # G·ª£i √Ω 3: Generic v·ªõi timestamp
        timestamp = datetime.now().strftime("%d/%m")
        suggestions.append(f"Tuy·ªÉn d·ª•ng {timestamp}")
        
        # G·ª£i √Ω 4: Theo level
        if any(word in job_description.lower() for word in ['senior', 'lead', 'principal', 'tr∆∞·ªüng']):
            suggestions.append(f"Tuy·ªÉn Senior Developer")
        elif any(word in job_description.lower() for word in ['junior', 'fresher', 'intern', 'm·ªõi']):
            suggestions.append(f"Tuy·ªÉn Junior Developer")
        else:
            suggestions.append(f"Tuy·ªÉn Developer")
        
        return suggestions[:3]  # Ch·ªâ tr·∫£ v·ªÅ 3 g·ª£i √Ω ƒë·∫ßu
        
    except Exception as e:
        logger.error(f"L·ªói t·∫°o session title suggestions: {e}")
        return ["Tuy·ªÉn d·ª•ng m·ªõi", "Phi√™n tuy·ªÉn d·ª•ng", "T√¨m ·ª©ng vi√™n"]